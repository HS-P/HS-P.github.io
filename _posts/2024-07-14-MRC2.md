---
title: 방학 MRC 준비(1)
date: 2024-07-21 13:00:00 +0900
categories: ["2024", "MRC"]
pin: true
---

# 국방로봇 경진대회 Research Diary #3

이번 학기 점수는 4.45로, 과에서 2등을 기록했다.  
(목표한 바는 못 채워 아쉬웠지만 그래도 만족할만한 결과다.)

## 부제 : 학기 후 계획

7월에 이르러, 본인은 Computer Vision에 본격적으로 돌입했다.  
그러나, 가장 큰 문제가 발생했다.  
부품이 7월 22일에 되어서야 주문이 완료된다는 이야기를 들었고, 사실상 8월이 되어서야 물품을 받을 수 있다는 걸 알게 되었다.

문제는 7월 28일까지 제출해야하는 보고서 때문이다. 국방로봇 경진대회 예선 보고서 제출이 7월 28일까지이므로, 모든 부품이 도착하지 않은 상태에서 영상 및 보고서를 작성해야 하는 상황이 온 것이다.

그냥 하면 되겠지만, 문제는 예선 보고서에 작성한 내용이 정확한지, 명확한 지에 대해 잘 모르는 것이 문제다.  
(혹여 내가 잘못된 내용을 작성하게 될까봐 걱정이다.)

![Image](/posts/mrc007.png)

하드웨어는 도색 작업을 정상적으로 진행하고 있다.

---

### Jetson Tx2

일단, 지금까지 Jetson Tx2의 단점의 문제가 부각되었다.  
나는 Jetson Tx2가 EOL(End Of Life)인건 알고 있었다. 사실상, 크게 지원 없이 Ubuntu 18.04 환경에서 개발하면 된다고만 생각하고 있었다.  
(어쩌면, 오히려 더 효율적일 수도 있을 것이라 생각했다.)

그러나, OPENCV4, YOLO V8,V9와 V10이 출시되면서 상황은 달라졌다. 코드가 훨씬 압축되고, 효율적인 Filtering을 제공하며,수많은 기능들이 추가되고 있다.

Jetson Tx2에서는 이를 사용할 수 없는게 가장 큰 문제이다. Ubuntu 18.04에서는 Python도 3.6까지 지원하며, 강제로 3.7로 업그레이드하자 오히려 다른 패키지들도 충돌나며 오류가 발생했다.

그럼 Ubuntu 20.04를 사용하면 되는 것이 아니냐는 이야기가 있을 수도 있지만, 이는 불가능하다.  
Jetpack을 강제로 업그레이드를 하지 않는 한 Ubuntu 20.04는 불가능하고, Jetpack 역시 Nvidia에서 제공해주는 SDK이므로 함부로 업그레이드를 할 수 없었다.

![Image](/posts/mrc009.png)

Jetson Tx2는 YOLO의 고버전 지원 대상에서 제외되었다.  
(using Pytorch)

물론, 그렇다고 해서 포기하진 않았다.

![Image](/posts/mrc010.png)

_출처 : [Bechmark](https://jstar0525.tistory.com/57)_

Nano와 Tx2는 Yolo 저 버전 기준 두 배 가까이 차이난다. 일부 모델에 한해서는 두 배 이상 나기도 하는데, Xavier와 Orin의 가격을 생각한다면 가장 효율적인 모델은 역시 Tx2일 것이다.

본 연구실에서 가지고 있는 건 본 필자 소유의 Tx2와 Nano, Orin이다. Orin이 타 대회에서 사용되므로, Nano를 사용하기보다는 Orin을 사용하는 편이 훨씬 효율적일 것이다.

자, 그렇다면 여기서 내가 할 수 있는 건 무엇일까?  
Jetson Tx2에서 Yolo 저버전의 필터를 사용하면 될 것이라고 생각했다.  
Nano의 필터가 아무리 좋다 한듯 기존 성능이 낮으므로, Jetson Tx2(버전이 낮아 조금은 어려울 수 있겠지만) 잘 사용할 수 있을 것이라고 생각한다.

---

#### Yolo V4 Project 진행

---

사실, 이미 Jetson Tx2의 Ubuntu를 두 번은 날려먹었다.

1. 용량 부족. (32GB Micro SD Card 사용 중)
2. Library 충돌 (강제 Install 과정)

그래서 [Ros2 Project](https://docs.ros.org/en/dashing/Related-Projects/Intel-ROS2-Projects.html)에서 Intel Camera Project를 진행하기로 했다.  
제우스 경진대회는 9월이고, 예선이 통과해야 로봇이 도착해서 카메라를 사용하므로 그때까지는 D455 카메라가 연구실에 1대 남아서 사용이 가능하다.  
그래서 사용을 했고, D455 Camera를 사용하기 위한 ROS2 wrapper를 설치했다.

이후, Object Detection을 진행하기로 했다. ROS2 Darknet, Yolov4가 최대였고, Yolo V5이상과 V8 이상의 Ref를 찾아보았으나 정상적으로 작동하기에는 어려웠다. (Python, Cuda 등 버전의 차이로 인해)

![Image](/posts/mrc011.png)  
_[Realsense Github](https://github.com/intel/ros2_object_analytics)_

해당 프로젝트를 정상적으로 따라가도 어려운 일들이 많았다. 이유는 간단하다.

내 환경은 Computer (Ubuntu 22.04, Ros2 Humble)이고,  
SBC의 환경은 Jetson Tx2 (Ubuntu 18.04, Ros2 Dashing)이다.

서로 Node를 공유하며 Topic을 Susbscribe해 Computer에서 ssh로 연결해 확인하는 과정이 생각보다 원활하지 않았는데 Qos 설정에서 Depth값을 늘리고, Image Raw를 Susbscribe 하는 것을 Compressed로 변경하여 훨씬 더 FPS를 늘렸다.(말로는 한 줄에 끝났지만, 실제로는 2주 가까이 걸렸다.)

결과값은 아래와 같다.

![Image](/posts/mrc012.jpg)

기본 Dataset으로, 이제 해야할 일에 대한 Ref는 Notion에 정리해 두었다.

1. Dataset에 사용할 사진 찍기 (Vision Marker, Box, 국방부 옷) 각 Class별 1000장
2. [Colab과 Darknet으로 YOLO 학습시키기](https://hipolarbear.tistory.com/41)
3. [학습시킬 Dataset Labeling In roboflow](https://hipolarbear.tistory.com/38)
